# ‚úÖ Google Sheets Scraper - Setup Complete!

## üéØ What Changed

I've replaced the PCSO website scraper with a **Google Sheets scraper** that reads historical lottery data directly from your Google Sheets.

---

## ‚úÖ Changes Made

### 1. **New Scraper** (`backend/scrapers/google_sheets_scraper.py`)
- ‚úÖ Reads data from Google Sheets (public or private)
- ‚úÖ Parses lottery results (combinations, dates, jackpots, winners)
- ‚úÖ Checks for duplicates in InstantDB
- ‚úÖ Only adds new data to database
- ‚úÖ Works with public sheets (no credentials needed)

### 2. **Updated Configuration** (`backend/config.py`)
- ‚úÖ Added Google Sheets IDs for all 5 games
- ‚úÖ Removed PCSO scraping configuration

### 3. **Updated API** (`backend/app.py`)
- ‚úÖ Changed to use Google Sheets scraper
- ‚úÖ Removed date parameters (reads all data from sheets)

### 4. **Updated Dependencies** (`backend/requirements.txt`)
- ‚úÖ Added `gspread` and `google-auth` (optional - works without them for public sheets)

---

## üìä Google Sheets Configuration

Your sheets are configured:

| Game | Sheet ID | URL |
|------|----------|-----|
| Ultra Lotto 6/58 | `1gh6yxZuaaCdx1imvJuk0-wXtMic4fcdm` | [View Sheet](https://docs.google.com/spreadsheets/d/1gh6yxZuaaCdx1imvJuk0-wXtMic4fcdm) |
| Grand Lotto 6/55 | `1kuWordaccnhHATdaZr-qRhDPhPzxhcSU` | [View Sheet](https://docs.google.com/spreadsheets/d/1kuWordaccnhHATdaZr-qRhDPhPzxhcSU) |
| Super Lotto 6/49 | `1tlAyfbtRTMXVWP-sk6V4jVW1fteZtMmq` | [View Sheet](https://docs.google.com/spreadsheets/d/1tlAyfbtRTMXVWP-sk6V4jVW1fteZtMmq) |
| Mega Lotto 6/45 | `1ydlcaUk_DG3XLPRcHk23tXBWvC83uPxH` | [View Sheet](https://docs.google.com/spreadsheets/d/1ydlcaUk_DG3XLPRcHk23tXBWvC83uPxH) |
| Lotto 6/42 | `1E7_PnmkJc5wDL8OnEd1aljoUm5iDzEf3` | [View Sheet](https://docs.google.com/spreadsheets/d/1E7_PnmkJc5wDL8OnEd1aljoUm5iDzEf3) |

---

## üöÄ Setup Instructions

### Step 1: Install Dependencies

```powershell
cd backend
.\venv\Scripts\Activate.ps1
pip install gspread google-auth
```

**Note:** If sheets are public, this is optional - the scraper will use CSV export.

### Step 2: (Optional) Set Up Google Service Account

If your sheets are **private**, you'll need Google credentials:

1. Go to [Google Cloud Console](https://console.cloud.google.com/)
2. Create a project (or use existing)
3. Enable Google Sheets API
4. Create a Service Account
5. Download JSON credentials file
6. Add to `.env`:
   ```env
   GOOGLE_SERVICE_ACCOUNT_FILE=path/to/credentials.json
   ```

**If sheets are public:** No credentials needed! ‚úÖ

### Step 3: Restart Server

```powershell
cd backend
uvicorn app:app --host 0.0.0.0 --port 5000 --reload
```

---

## üìã How It Works

### Data Format Expected

The scraper expects sheets with these columns:
- **LOTTO GAME**: Game name (e.g., "Superlotto 6/49")
- **COMBINATIONS**: Numbers separated by hyphens (e.g., "40-11-14-39-04-32")
- **DRAW DATE**: Date in M/D/YYYY format (e.g., "4/1/2015")
- **JACKPOT (PHP)**: Jackpot amount (e.g., "129,835,788.00")
- **WINNERS**: Number of winners (e.g., "0")

### Process

1. **Reads Google Sheet** (via CSV export for public sheets)
2. **Parses each row** into structured data
3. **Checks InstantDB** for existing results
4. **Adds only new data** (by draw date)
5. **Saves to InstantDB** for analysis

---

## üß™ Testing

### Test the Scraper

1. **Start your server**
2. **Call the scrape endpoint** from your frontend or:
   ```powershell
   curl -X POST "http://localhost:5000/api/scrape" -H "Content-Type: application/json" -d "{}"
   ```

### Expected Output

```json
{
  "success": true,
  "stats": {
    "total_games": 5,
    "games": {
      "ultra_lotto_6_58": {
        "game_name": "Ultra Lotto 6/58",
        "total_in_sheet": 150,
        "existing_in_db": 100,
        "new_results": 50,
        "added": 50
      },
      ...
    },
    "summary": {
      "total_results_in_sheets": 750,
      "total_existing_in_db": 500,
      "total_new_results": 250,
      "total_added": 250
    }
  }
}
```

---

## üîÑ Automatic Updates

### How to Trigger Updates

When new data is added to Google Sheets:

1. **Call the `/api/scrape` endpoint** (from frontend or scheduled job)
2. **Scraper checks for new data**
3. **Only new entries are added** to InstantDB
4. **Analysis runs on InstantDB data**

### Scheduled Updates (Optional)

You can set up a scheduled task to check for updates:

```python
# Example: Check every hour
import schedule
import time

def check_for_updates():
    scraper = GoogleSheetsScraper()
    stats = await scraper.scrape_all_games()
    print(f"Added {stats['summary']['total_added']} new results")

schedule.every().hour.do(check_for_updates)
```

---

## üìù Data Structure

### Sheet Format

```
| LOTTO GAME      | COMBINATIONS      | DRAW DATE | JACKPOT (PHP)  | WINNERS |
|-----------------|-------------------|-----------|----------------|---------|
| Superlotto 6/49 | 40-11-14-39-04-32 | 4/1/2015  | 129,835,788.00 | 0       |
```

### InstantDB Format

```json
{
  "draw_date": "2015-04-01T00:00:00",
  "number_1": 4,
  "number_2": 11,
  "number_3": 14,
  "number_4": 32,
  "number_5": 39,
  "number_6": 40,
  "jackpot": 129835788.0,
  "winners": 0
}
```

---

## ‚úÖ Benefits

1. **No KYC Required** ‚úÖ - No Bright Data needed
2. **No Bot Detection** ‚úÖ - Direct data access
3. **Reliable** ‚úÖ - Google Sheets is stable
4. **Easy Updates** ‚úÖ - Just add data to sheets
5. **Automatic Deduplication** ‚úÖ - Only new data added

---

## üéØ Next Steps

1. **Install dependencies**: `pip install gspread google-auth`
2. **Restart server**
3. **Test scraping**: Call `/api/scrape` endpoint
4. **Verify data**: Check InstantDB for new results
5. **Run analysis**: Use existing ML models on InstantDB data

---

## üìä Summary

| Component | Status |
|-----------|--------|
| Google Sheets Scraper | ‚úÖ Created |
| Configuration | ‚úÖ Updated |
| API Endpoint | ‚úÖ Updated |
| Dependencies | ‚úÖ Added |
| Ready to Use | ‚úÖ YES! |

**Everything is ready! Just install dependencies and restart your server!** üöÄ

